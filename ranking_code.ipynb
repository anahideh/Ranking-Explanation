{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statistics\n",
    "#import docplex.mp.model as cplex\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "pd.set_option('chained_assignment',None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "timesData = pd.read_csv('timesData.csv')\n",
    "\n",
    "\n",
    "timesData2 = pd.read_csv('times2-revised.csv')\n",
    "\n",
    "\n",
    "timesData=timesData._append(timesData2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atr=[\"world_rank\",\"university_name\",\"teaching\",\"international\",\"research\",\"citations\",\"income\",\"total_score\",\"year\"]\n",
    "\n",
    "timesData=timesData[atr]\n",
    "timesData=timesData.reset_index(drop=True)\n",
    "\n",
    "# data cleaning\n",
    "# timesData.international = timesData.international.str.replace('-', '')\n",
    "timesData.world_rank = timesData.world_rank.str.replace('=', '')\n",
    "timesData.world_rank = timesData.world_rank.str.split('-').str[0]\n",
    "timesData.world_rank = timesData.world_rank.str.split('+').str[0]\n",
    "timesData.world_rank = timesData.world_rank.str.split('–').str[0]\n",
    "timesData.world_rank = timesData.world_rank.str.split('—').str[0]#this line is not duplicated\n",
    "timesData.total_score = timesData.total_score.str.split('—').str[0]\n",
    "timesData.total_score = timesData.total_score.str.split('–').str[0]\n",
    "\n",
    "\n",
    "timesData.international = timesData.international.replace('-', np.nan)\n",
    "timesData.total_score = timesData.total_score.replace('-', np.nan)\n",
    "timesData.income = timesData.income.replace('-', np.nan)\n",
    "\n",
    "\n",
    "#fill in NAN value with previous value \n",
    "timesData.isnull().any()\n",
    "timesData =timesData.fillna(method='ffill')\n",
    "timesData=timesData.reset_index(drop=True)\n",
    "\n",
    "# convert all data to numerical values \n",
    "timesData['teaching'] = timesData['teaching'].astype(float)\n",
    "\n",
    "timesData['international'] = timesData['international'].astype(float)\n",
    "\n",
    "timesData['research'] = timesData['research'].astype(float)\n",
    "\n",
    "timesData['citations'] = timesData['citations'].astype(float)\n",
    "timesData['income'] = timesData['income'].astype(float)\n",
    "\n",
    "timesData['total_score'] = timesData['total_score'].astype(float)\n",
    "timesData['world_rank'] = timesData['world_rank'].astype(int)\n",
    "\n",
    "# drop colleges with no total scores\n",
    "noScores = timesData[ timesData['world_rank'] > 198].index\n",
    "timesData.drop(noScores , inplace=True)\n",
    "\n",
    "df = timesData[timesData.year == 2016]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - FUNCTIONS -\n",
    "\n",
    "# begin create function\n",
    "def createNeighborhood(collegeIndex, s):\n",
    "    # function creates a neighborhood of size s around collegeIndex given\n",
    "    neighborhood = []\n",
    "    for x in range(s, 0, -1):\n",
    "        if collegeIndex - x > 0:\n",
    "            neighborhood.append(collegeIndex - x)\n",
    "    neighborhood.append(collegeIndex)\n",
    "    for x in range(1, s + 1):\n",
    "        if collegeIndex + x < 203:\n",
    "            neighborhood.append(collegeIndex + x)\n",
    "    return neighborhood\n",
    "# end create function\n",
    "    \n",
    "# BEGIN OLS FUNCTION\n",
    "def identify_most_sig_feature_OLS(neighborhood_array, sig_values):\n",
    "    # Function uses OLS to find mose contributing features. It returns a 2D \n",
    "    # array of each feature in order in most contributing to least of size \n",
    "    # parameter 'sig_values'\n",
    "    \n",
    "    coefficents = []\n",
    "    \n",
    "    first = neighborhood_array[0]\n",
    "    last = neighborhood_array[-1]\n",
    "    \n",
    "    X = df.loc[1802 + first : 1801 + last,\"teaching\":\"income\"]\n",
    "    y = df.loc[1802 + first : 1801 + last, \"total_score\"]\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    #append all coeffecients\n",
    "    coefficents.append([results.params[0], \"teaching\"])\n",
    "    coefficents.append([results.params[1], \"international\"])\n",
    "    coefficents.append([results.params[2], \"research\"])\n",
    "    coefficents.append([results.params[3], \"citations\"])\n",
    "    coefficents.append([results.params[4], \"income\"])\n",
    "    #sort coefficents from greatest to least\n",
    "    coefficents.sort(reverse = True) \n",
    "    return(coefficents[0:sig_values])\n",
    "# END OLS FUNCTION\n",
    "\n",
    "\n",
    "def vip(x, y, model):\n",
    "    t = model.x_scores_\n",
    "    w = model.x_weights_\n",
    "    q = model.y_loadings_\n",
    "\n",
    "    m, p = x.shape\n",
    "    _, h = t.shape\n",
    "\n",
    "    vips = np.zeros((p,))\n",
    "\n",
    "    s = np.diag(t.T @ t @ q.T @ q).reshape(h, -1)\n",
    "    total_s = np.sum(s)\n",
    "\n",
    "    for i in range(p):\n",
    "        weight = np.array([ (w[i,j] / np.linalg.norm(w[:,j]))**2 for j in range(h) ])\n",
    "        vips[i] = np.sqrt(p*(s.T @ weight)/total_s)\n",
    "\n",
    "    return vips\n",
    "\n",
    "# BEGIN PLS FUNCTION\n",
    "def identify_most_sig_feature_PLS(neighborhood_array, sig_values):\n",
    "    # Function uses PLS to find mose contributing features. It returns a 2D \n",
    "    # array of each feature in order in most contributing to least of size \n",
    "    # parameter 'sig_values'\n",
    "\n",
    "    coefficents = []\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    first = neighborhood_array[0]\n",
    "    last = neighborhood_array[-1]\n",
    "    \n",
    "    X = df.loc[first : last,\"teaching\":\"income\"]\n",
    "    y = df.loc[first : last, \"world_rank\"]\n",
    "    pls = PLSRegression(n_components= 5) \n",
    "    pls.fit(X, y)\n",
    " \n",
    "    \n",
    "    #append all coeffecients\n",
    "    con = len(neighborhood_array)\n",
    "    coefficents.append(pls.coef_[0][0]/con)\n",
    "    coefficents.append(pls.coef_[0][1]/con)\n",
    "    coefficents.append(pls.coef_[0][2]/con)\n",
    "    coefficents.append(pls.coef_[0][3]/con)\n",
    "    coefficents.append(pls.coef_[0][4]/con)\n",
    "    #sort coefficents from greatest to least\n",
    "    #coefficents.sort(reverse = True)\n",
    "    output=vip(X, y, pls)\n",
    "    return(output)\n",
    "    \n",
    "    \n",
    "# END PLS FUNCTION\n",
    "\n",
    "def transitionProbability(startRank, endRank):\n",
    "    count = 0\n",
    "    for x in range(2011, 2020):\n",
    "        df = timesData[timesData.year == x]\n",
    "#         df.world_rank = df.world_rank.str.replace('=', '')\n",
    "#         df.world_rank = df.world_rank.str.split('-').str[0]\n",
    "#         df['world_rank'] = df['world_rank'].astype(int)\n",
    "        df = df.iloc[startRank-1,1]\n",
    "    \n",
    "        df1 = timesData[timesData.year == x+1]\n",
    "#         df1.world_rank = df1.world_rank.str.replace('=', '')\n",
    "#         df1.world_rank = df1.world_rank.str.split('-').str[0]\n",
    "#         df1['world_rank'] = df1['world_rank'].astype(int)\n",
    "        df1 = df1.iloc[endRank-1,1]\n",
    "    \n",
    "        if df == df1:\n",
    "            count += 1\n",
    "    pr = count/5.0\n",
    "    return pr\n",
    "\n",
    "def transitionProbabilityBetweenNeighborhood(neighborhoodIndex, neighborhoodSizeOne, neighborhoodSizeTwo):\n",
    "    count = 0\n",
    "    for x in range(2011, 2020):\n",
    "        N=createNeighborhood(neighborhoodIndex,neighborhoodSizeOne)\n",
    "        for n in N:\n",
    "            for c in range(neighborhoodIndex-neighborhoodSizeTwo, neighborhoodIndex-neighborhoodSizeOne):\n",
    "                df = timesData[timesData.year == x]\n",
    "#                 df.world_rank = df.world_rank.str.replace('=', '')\n",
    "#                 df.world_rank = df.world_rank.str.split('-').str[0]\n",
    "#                 df['world_rank'] = df['world_rank'].astype(int)\n",
    "                df = df.iloc[n-1,1]\n",
    "                \n",
    "    \n",
    "                df1 = timesData[timesData.year == x+1]\n",
    "#                 df1.world_rank = df1.world_rank.str.replace('=', '')\n",
    "#                 df1.world_rank = df1.world_rank.str.split('-').str[0]\n",
    "#                 df1['world_rank'] = df1['world_rank'].astype(int)\n",
    "                df1 = df1.iloc[c-1,1]\n",
    "                if df == df1:\n",
    "                    count += 1\n",
    "    pr = count / (len(N) * 5.0)\n",
    "    return pr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Framework\n",
    "unis=7  # 7\n",
    "universityRank = [5,15,25,45,65,85,100] #5,15,25,45,65,85,100  1,2,6,14\n",
    "numberOfNeighborhood = 3\n",
    "sizeOfNeighborhoodList = [5,10,15,30,100,150,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot=[]\n",
    "j=0\n",
    "for j in range(0,unis):\n",
    "    PLS=[]\n",
    "    for i in range (0, numberOfNeighborhood):\n",
    "        neighborhood = createNeighborhood(universityRank[j], sizeOfNeighborhoodList[i])\n",
    "        PLS.append(identify_most_sig_feature_PLS(neighborhood, 5))\n",
    "    PLS=pd.DataFrame(PLS)\n",
    "    tot.append(PLS)\n",
    "    data_pls = pd.concat(tot, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "           \n",
    "def identify_most_sig_feature_dctree(neighborhood_array, sig_values):\n",
    "\n",
    "    coefficents = []\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    first = neighborhood_array[0]\n",
    "    last = neighborhood_array[-1]\n",
    "\n",
    "    X = df.loc[first : last,\"teaching\":\"income\"]\n",
    "    y = df.loc[first : last, \"world_rank\"]\n",
    "    #     pls = PLSRegression(n_components= 5) \n",
    "    treeregr = DecisionTreeRegressor(max_depth=2)\n",
    "\n",
    "    treeregr.fit(X, y)\n",
    "\n",
    "    importance = treeregr.feature_importances_\n",
    "\n",
    "    return(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot=[]\n",
    "j=0\n",
    "for j in range(0,unis):\n",
    "    tree=[]\n",
    "    for i in range (0, numberOfNeighborhood):\n",
    "        neighborhood = createNeighborhood(universityRank[j], sizeOfNeighborhoodList[i])\n",
    "        tree.append(identify_most_sig_feature_dctree(neighborhood, 5))\n",
    "    tree=pd.DataFrame(tree)\n",
    "    tot.append(tree)\n",
    "    data_dct = pd.concat(tot, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_most_sig_feature_LR(neighborhood_array):\n",
    "    # Function uses linear regression to find most contributing features. It returns a 2D \n",
    "    # array of each feature in order in most contributing to least of size \n",
    "    # parameter 'sig_values'\n",
    "   \n",
    "\n",
    "    first = neighborhood_array[0]\n",
    "    last = neighborhood_array[-1]\n",
    "    \n",
    "    X = df.loc[first : last,\"teaching\":\"income\"]\n",
    "    y = df.loc[first : last, \"world_rank\"]     # why rank and not score?\n",
    "    \n",
    "   \n",
    "    LRreg = LinearRegression()\n",
    "    LRreg.fit(X, y)\n",
    "    \n",
    "    # get importance\n",
    "    importance = LRreg.coef_\n",
    "    #score=LRreg.score(X, y)\n",
    "    #print(score)\n",
    "    \n",
    "    \n",
    "    #reproduce this with linear algebra\n",
    "    N = len(X)\n",
    "    p = len(X.columns) + 1  # plus one because LinearRegression adds an intercept term\n",
    "\n",
    "    X_with_intercept = np.empty(shape=(N, p))\n",
    "    X_with_intercept[:, 0] = 1\n",
    "    X_with_intercept[:, 1:p] = X.values\n",
    "\n",
    "    beta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ X_with_intercept.T @ y.values\n",
    "    #print(beta_hat)\n",
    "    \n",
    "    #compute standard errors of the parameter estimates\n",
    "    y_hat = LRreg.predict(X)\n",
    "    residuals = y.values - y_hat\n",
    "    residual_sum_of_squares = residuals.T @ residuals\n",
    "    sigma_squared_hat = residual_sum_of_squares / (N - p)\n",
    "    var_beta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) * sigma_squared_hat\n",
    "    SEV=[]\n",
    "    for p_ in range(p):\n",
    "        standard_error = var_beta_hat[p_, p_] ** 0.5\n",
    "        print(f\"SE(beta_hat[{p_}]): {standard_error}\")\n",
    "        SEV.append(standard_error)\n",
    "    \n",
    "    #print(SEV)\n",
    "    standard_error_vector = np.delete(SEV, [0])\n",
    "    \n",
    "    t_statistic = (importance/standard_error)\n",
    "    #print(importance)\n",
    "    #print(standard_error_vector)\n",
    "    #print(t_statistic)\n",
    "  \n",
    "    return(t_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot=[]\n",
    "j=0\n",
    "for j in range(0,unis):\n",
    "    LR=[]\n",
    "    for i in range (0, numberOfNeighborhood):\n",
    "        neighborhood = createNeighborhood(universityRank[j], sizeOfNeighborhoodList[i])\n",
    "        LR.append(identify_most_sig_feature_LR(neighborhood))\n",
    "        #print(neighborhood)\n",
    "    LR=pd.DataFrame(LR)\n",
    "\n",
    "    tot.append(LR)\n",
    "    data_LR = pd.concat(tot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.shapley import ShapleyValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = ShapleyValue(df, [\n",
    "            'teaching','international','research','citations','income'\n",
    "        ],\n",
    "        'total_score'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot=[]\n",
    "j=0\n",
    "atr=['teaching','international','research','citations','income']\n",
    "for j in range(0,unis):\n",
    "    SV=[]\n",
    "    for i in range (0, numberOfNeighborhood):\n",
    "        neighborhood = createNeighborhood(universityRank[j], sizeOfNeighborhoodList[i])\n",
    "        sv = ShapleyValue(df.iloc[neighborhood], atr,'world_rank')\n",
    "        cont=sv.get_shapley_contribution()\n",
    "        SV.append(cont[atr].values[0])\n",
    "    SV=pd.DataFrame(SV)\n",
    "    tot.append(SV)\n",
    "    data_SV = pd.concat(tot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_most_sig_feature_Lime(neighborhood,sizeOfNeighborhoodList):\n",
    "\n",
    "    first = neighborhood[0]\n",
    "    last = neighborhood[-1]\n",
    "\n",
    "    X = df.loc[first : last,\"teaching\":\"income\"]\n",
    "    y = df.loc[first : last, \"world_rank\"]   \n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "\n",
    "    \n",
    "    # This works with X_Train data\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=np.array(X),\n",
    "        feature_names=X.columns,\n",
    "        class_names=['world_rank'],\n",
    "        mode='regression'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ika = sizeOfNeighborhoodList \n",
    "    # This works with X_Test data:  Should ika be the university under study???### HA: I think yes but now it is neighborhood size\n",
    "    exp = explainer.explain_instance(\n",
    "        data_row=X.iloc[ika],\n",
    "        predict_fn=model.predict #model.predict_proba\n",
    "    )\n",
    "    \n",
    "    a=exp.as_list()\n",
    "  \n",
    "\n",
    "    exp.show_in_notebook(show_table=True)\n",
    "    \n",
    "    print('a is :', a)\n",
    "\n",
    "    #['teaching','international','research','citations','income']\n",
    "    imp=[0] * 5 \n",
    "    for i in range(0,5):\n",
    "        s = a[i][0]\n",
    "        result = re.search('< (.*) <=', s)\n",
    "    #     print(result)\n",
    "        if result==None:\n",
    "            result = re.search('(.*) >', s)\n",
    "        if result==None:\n",
    "            result = re.search('(.*) <=', s)\n",
    "        if result.group(1)== 'research':\n",
    "            imp[2]=a[i][1]\n",
    "        if result.group(1)== 'international':\n",
    "            imp[1]=a[i][1] \n",
    "        if result.group(1)== 'teaching':\n",
    "            imp[0]=a[i][1]\n",
    "        if result.group(1)== 'citations':\n",
    "            imp[3]=a[i][1]\n",
    "        if result.group(1)== 'income':\n",
    "            imp[4]=a[i][1]\n",
    "\n",
    "     # you need to call random.seed before calling explain_instance each time.\n",
    "     #   I tried setting a seed but for all instances in the j loop it gives the same answer!!\n",
    "        \n",
    " #   def explain(instance, predict_fn,ika):\n",
    " #       np.random.seed(16)\n",
    " #       exp = explainer.explain_instance(data_row=X.iloc[ika], predict_fn=model.predict)\n",
    " #   return exp\n",
    " #   a=exp.as_list()\n",
    "\n",
    "\n",
    "\n",
    "# Prediction_local is intercept + weights * features.\n",
    "#the weights are relative to the scaled data, so your feature_value column should be scaled. \n",
    "#You can get the scaled values by running:\n",
    "    #b = (X.iloc[ika] - explainer.scaler.mean_) / explainer.scaler.scale_\n",
    "\n",
    "#TabularExplainer discretizes continuous features by default (discretize_continuous=True in init).    \n",
    "#https://github.com/marcotcr/lime/issues/189\n",
    "    \n",
    "    \n",
    "    \n",
    " #   for runner in exp.as_list():\n",
    "  #      print(runner[0], \"\\t\", runner[1])\n",
    "\n",
    "    return(imp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l=[]\n",
    "tot=[]\n",
    "j=0\n",
    "for j in range(0,unis):\n",
    "    LR=[]\n",
    "    for i in range (0, numberOfNeighborhood):\n",
    "        neighborhood = createNeighborhood(universityRank[j], sizeOfNeighborhoodList[i])\n",
    "        a = identify_most_sig_feature_Lime(neighborhood,sizeOfNeighborhoodList[i])\n",
    "        print(a)\n",
    "        LR.append(a)\n",
    "    LR=pd.DataFrame(LR)\n",
    "\n",
    "    tot.append(LR)\n",
    "    data_Lime = pd.concat(tot, axis=1)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#['teaching','international','research','citations','income']\n",
    "imp=[0] * 5 \n",
    "for i in range(0,5):\n",
    "    s = a[i][0]\n",
    "    result = re.search('< (.*) <=', s)\n",
    "#     print(result)\n",
    "    if result==None:\n",
    "        result = re.search('(.*) >', s)\n",
    "    if result==None:\n",
    "        result = re.search('(.*) <=', s)\n",
    "    if result.group(1)== 'research':\n",
    "        imp[2]=a[i][1]\n",
    "    if result.group(1)== 'international':\n",
    "        imp[1]=a[i][1] \n",
    "    if result.group(1)== 'teaching':\n",
    "        imp[0]=a[i][1]\n",
    "    if result.group(1)== 'citations':\n",
    "        imp[3]=a[i][1]\n",
    "    if result.group(1)== 'income':\n",
    "        imp[4]=a[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###heatmap for OLS\n",
    "from mpl_toolkits.axes_grid.parasite_axes import SubplotHost\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# fig, ax = plt.subplots(1,1,figsize=(20,7.5))\n",
    "fig1 = plt.figure(figsize=(20,5))\n",
    "ax1 = SubplotHost(fig1, 111)\n",
    "fig1.add_subplot(ax1)\n",
    "\n",
    "ax1.imshow(data_ols, cmap=plt.cm.get_cmap('Blues', 6), interpolation='nearest',aspect='auto')\n",
    "# ax.colorbar(extend='both')\n",
    "img = ax1.imshow(data_ols, cmap=plt.cm.get_cmap('Blues', 6), interpolation='nearest',aspect='auto')\n",
    "\n",
    "x_label_list = [r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$']\n",
    "y_label_list = ['$\\mathcal{H}_1$','$\\mathcal{H}_2$','$\\mathcal{H}_3$']\n",
    "ax1.set_xticks(np.arange(0,35))\n",
    "ax1.set_yticks([  0,  1,  2])\n",
    "ax1.set_xticklabels(x_label_list)\n",
    "ax1.set_yticklabels(y_label_list)\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# Second X-axis\n",
    "ax2 = ax1.twiny()\n",
    "offset = 0, -35 # Position of the second axis\n",
    "new_axisline = ax2.get_grid_helper().new_fixed_axis\n",
    "ax2.axis[\"bottom\"] = new_axisline(loc=\"bottom\", axes=ax2, offset=offset)\n",
    "ax2.axis[\"top\"].set_visible(False)\n",
    "\n",
    "ax2.set_xticks([ 0, 5, 10, 15, 20, 25, 30, 35])\n",
    "ax2.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax2.xaxis.set_minor_locator(ticker.FixedLocator([2, 7,12,17,22,27,32]))\n",
    "ax2.xaxis.set_minor_formatter(ticker.FixedFormatter(['Uni.52', 'Uni.55','Uni.57', 'Uni.60','Uni.62','Uni.65','Uni.71']))\n",
    "fig1.colorbar(img,cax=cax)\n",
    "plt.show() 5,15,25,45,65,85,100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###heatmap for PLS\n",
    "from mpl_toolkits.axes_grid.parasite_axes import SubplotHost\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# fig, ax = plt.subplots(1,1,figsize=(20,7.5))\n",
    "fig1 = plt.figure(figsize=(20,5))\n",
    "ax1 = SubplotHost(fig1, 111)\n",
    "fig1.add_subplot(ax1)\n",
    "\n",
    "ax1.imshow(data_pls, cmap=plt.cm.get_cmap('Blues', 6), interpolation='nearest',aspect='auto')\n",
    "# ax.colorbar(extend='both')\n",
    "img = ax1.imshow(data_pls, cmap=plt.cm.get_cmap('Blues', 6), interpolation='nearest',aspect='auto')\n",
    "\n",
    "x_label_list = [r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$']\n",
    "y_label_list = ['$\\mathcal{H}_1$','$\\mathcal{H}_2$','$\\mathcal{H}_3$']\n",
    "ax1.set_xticks(np.arange(0,35))\n",
    "ax1.set_yticks([  0,  1,  2])\n",
    "ax1.set_xticklabels(x_label_list)\n",
    "ax1.set_yticklabels(y_label_list)\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# Second X-axis\n",
    "ax2 = ax1.twiny()\n",
    "offset = 0, -35 # Position of the second axis\n",
    "new_axisline = ax2.get_grid_helper().new_fixed_axis\n",
    "ax2.axis[\"bottom\"] = new_axisline(loc=\"bottom\", axes=ax2, offset=offset)\n",
    "ax2.axis[\"top\"].set_visible(False)\n",
    "\n",
    "ax2.set_xticks([ 0, 5, 10, 15, 20, 25, 30, 35])\n",
    "ax2.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax2.xaxis.set_minor_locator(ticker.FixedLocator([2, 7,12,17,22,27,32]))\n",
    "ax2.xaxis.set_minor_formatter(ticker.FixedFormatter(['Uni.4', 'Uni.7','Uni.13', 'Uni.17','Uni.62','Uni.65','Uni.71']))\n",
    "fig1.colorbar(img,cax=cax)\n",
    "plt.show() 5,15,25,45,65,85,100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###heatmap for Decision tree\n",
    "from mpl_toolkits.axes_grid.parasite_axes import SubplotHost\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# fig, ax = plt.subplots(1,1,figsize=(20,7.5))\n",
    "fig1 = plt.figure(figsize=(20,5))\n",
    "ax1 = SubplotHost(fig1, 111)\n",
    "fig1.add_subplot(ax1)\n",
    "\n",
    "ax1.imshow(data_dct, cmap=plt.cm.get_cmap('Blues', 6), interpolation='nearest',aspect='auto')\n",
    "# ax.colorbar(extend='both')\n",
    "img = ax1.imshow(data_dct, cmap=plt.cm.get_cmap('Blues', 6), interpolation='nearest',aspect='auto')\n",
    "\n",
    "x_label_list = [r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$']\n",
    "y_label_list = ['$\\mathcal{H}_1$','$\\mathcal{H}_2$','$\\mathcal{H}_3$']\n",
    "ax1.set_xticks(np.arange(0,35))\n",
    "ax1.set_yticks([  0,  1,  2])\n",
    "ax1.set_xticklabels(x_label_list)\n",
    "ax1.set_yticklabels(y_label_list)\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# Second X-axis\n",
    "ax2 = ax1.twiny()\n",
    "offset = 0, -35 # Position of the second axis\n",
    "new_axisline = ax2.get_grid_helper().new_fixed_axis\n",
    "ax2.axis[\"bottom\"] = new_axisline(loc=\"bottom\", axes=ax2, offset=offset)\n",
    "ax2.axis[\"top\"].set_visible(False)\n",
    "\n",
    "ax2.set_xticks([ 0, 5, 10, 15, 20, 25, 30, 35])\n",
    "ax2.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax2.xaxis.set_minor_locator(ticker.FixedLocator([2, 7,12,17,22,27,32]))\n",
    "ax2.xaxis.set_minor_formatter(ticker.FixedFormatter(['Uni.4', 'Uni.7','Uni.13', 'Uni.17','Uni.62','Uni.65','Uni.71']))\n",
    "fig1.colorbar(img,cax=cax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###heatmap for SHAP\n",
    "from mpl_toolkits.axes_grid.parasite_axes import SubplotHost\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# fig, ax = plt.subplots(1,1,figsize=(20,7.5))\n",
    "fig1 = plt.figure(figsize=(20,5))\n",
    "ax1 = SubplotHost(fig1, 111)\n",
    "fig1.add_subplot(ax1)\n",
    "\n",
    "ax1.imshow(data_SV, cmap=plt.cm.get_cmap('Blues', 6), interpolation='nearest',aspect='auto')\n",
    "# ax.colorbar(extend='both')\n",
    "img = ax1.imshow(data_SV, cmap=plt.cm.get_cmap('Blues', 6), interpolation='nearest',aspect='auto')\n",
    "\n",
    "x_label_list = [r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$']\n",
    "y_label_list = ['$\\mathcal{H}_1$','$\\mathcal{H}_2$','$\\mathcal{H}_3$']\n",
    "ax1.set_xticks(np.arange(0,35))\n",
    "ax1.set_yticks([  0,  1,  2])\n",
    "ax1.set_xticklabels(x_label_list)\n",
    "ax1.set_yticklabels(y_label_list)\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# Second X-axis\n",
    "ax2 = ax1.twiny()\n",
    "offset = 0, -55 # Position of the second axis\n",
    "new_axisline = ax2.get_grid_helper().new_fixed_axis\n",
    "ax2.axis[\"bottom\"] = new_axisline(loc=\"bottom\", axes=ax2, offset=offset)\n",
    "ax2.axis[\"top\"].set_visible(False)\n",
    "\n",
    "ax2.set_xticks([ 0, 5, 10, 15, 20, 25, 30, 35])\n",
    "ax2.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax2.xaxis.set_minor_locator(ticker.FixedLocator([2, 7,12,17,22,27,32]))\n",
    "ax2.xaxis.set_minor_formatter(ticker.FixedFormatter(['Uni.4', 'Uni.7','Uni.13', 'Uni.17','Uni.62','Uni.65','Uni.71']))\n",
    "fig1.colorbar(img,cax=cax)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###heatmap for Linear Regression\n",
    "from mpl_toolkits.axes_grid.parasite_axes import SubplotHost\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# fig, ax = plt.subplots(1,1,figsize=(20,7.5))\n",
    "fig1 = plt.figure(figsize=(20,5))\n",
    "ax1 = SubplotHost(fig1, 111)\n",
    "fig1.add_subplot(ax1)\n",
    "\n",
    "ax1.imshow(data_LR, cmap=plt.cm.get_cmap('Blues', 6), interpolation='nearest',aspect='auto')\n",
    "# ax.colorbar(extend='both')\n",
    "img = ax1.imshow(data_LR, cmap=plt.cm.get_cmap('Blues', 6), interpolation='nearest',aspect='auto')\n",
    "\n",
    "x_label_list = [r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$', \n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$',\n",
    "               r'$X_1$', r'$X_2$',r'$X_3$',r'$X_4$',r'$X_5$']\n",
    "y_label_list = ['$\\mathcal{H}_1$','$\\mathcal{H}_2$','$\\mathcal{H}_3$']\n",
    "ax1.set_xticks(np.arange(0,35))\n",
    "ax1.set_yticks([  0,  1,  2])\n",
    "ax1.set_xticklabels(x_label_list)\n",
    "ax1.set_yticklabels(y_label_list)\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# Second X-axis\n",
    "ax2 = ax1.twiny()\n",
    "offset = 0, -35 # Position of the second axis\n",
    "new_axisline = ax2.get_grid_helper().new_fixed_axis\n",
    "ax2.axis[\"bottom\"] = new_axisline(loc=\"bottom\", axes=ax2, offset=offset)\n",
    "ax2.axis[\"top\"].set_visible(False)\n",
    "\n",
    "ax2.set_xticks([ 0, 5, 10, 15, 20, 25, 30, 35])\n",
    "ax2.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax2.xaxis.set_minor_locator(ticker.FixedLocator([2, 7,12,17,22,27,32]))\n",
    "ax2.xaxis.set_minor_formatter(ticker.FixedFormatter(['Uni.4', 'Uni.7','Uni.13', 'Uni.17','Uni.62','Uni.65','Uni.71']))\n",
    "fig1.colorbar(img,cax=cax)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
